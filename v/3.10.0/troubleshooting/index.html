<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  <meta http-equiv="X-UA-Compatible" content="IE=edge">
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  
  <link rel="shortcut icon" href="../favicon.ico">
  
  <title>Troubleshooting - DataTorrent Documentation</title>
  <link href='https://fonts.googleapis.com/css?family=Lato:400,700|Roboto+Slab:400,700|Inconsolata:400,700' rel='stylesheet' type='text/css'>

  <link rel="stylesheet" href="../css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../css/theme_extra.css" type="text/css" />
  <link rel="stylesheet" href="../css/highlight.css">
  
  <script>
    // Current page data
    var mkdocs_page_name = "Troubleshooting";
    var mkdocs_page_input_path = "troubleshooting.md";
    var mkdocs_page_url = "/troubleshooting/";
  </script>
  
  <script src="../js/jquery-2.1.1.min.js" defer></script>
  <script src="../js/modernizr-2.8.3.min.js" defer></script>
  <script type="text/javascript" src="../js/highlight.pack.js" defer></script> 
  
  <script>
      (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
      (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
      m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
      })(window,document,'script','https://www.google-analytics.com/analytics.js','ga');

      ga('create', 'UA-44586211-2', 'docs.datatorrent.com');
      ga('send', 'pageview');
  </script>
  
</head>

<body class="wy-body-for-nav" role="document">

  <div class="wy-grid-for-nav">

    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side stickynav">
      <div class="wy-side-nav-search">
        <a href=".." class="icon icon-home"> DataTorrent Documentation</a>
        <div role="search">
  <form id ="rtd-search-form" class="wy-form" action="../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" title="Type search term here" />
  </form>
</div>
      </div>

      <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
	<ul class="current">
	  
          
            <li class="toctree-l1">
		
    <a class="" href="..">DataTorrent RTS</a>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Demos</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../demos/">Running Apps</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../sandbox/">Sandbox</a>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Cloud Integration</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../aws_emr_manual/">AWS</a>
                </li>
                <li class="">
                    
    <a class="" href="../azure_deployment/">Azure</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Development</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../create/">Creating Applications</a>
                </li>
                <li class="">
                    
    <a class="" href="../beginner/">Beginner's Guide</a>
                </li>
                <li class="">
                    
    <a class="" href="../demo_videos/">Videos</a>
                </li>
                <li class="">
                    
    <span class="caption-text">Tutorials</span>
    <ul class="subnav">
                <li class="toctree-l3">
                    
    <a class="" href="../tutorials/topnwords/">Top N Words</a>
                </li>
                <li class="toctree-l3">
                    
    <a class="" href="../tutorials/salesdemo/">Sales Dimensions</a>
                </li>
    </ul>
                </li>
                <li class="">
                    
    <a class="" href="../apex_development_setup/">Apex Development Setup</a>
                </li>
                <li class="">
                    
    <a class="" href="../configure_IDE/">Generate New Project in IDE</a>
                </li>
                <li class="">
                    
    <a class="" href="../application_development/">Applications</a>
                </li>
                <li class="">
                    
    <a class="" href="../application_packages/">Application Packages</a>
                </li>
                <li class="">
                    
    <a class="" href="../configuration_packages/">Configuration Packages</a>
                </li>
                <li class="">
                    
    <span class="caption-text">Operator Development</span>
    <ul class="subnav">
                <li class="toctree-l3">
                    
    <a class="" href="../operator_development/">Guide</a>
                </li>
                <li class="toctree-l3">
                    
    <a class="" href="../operator_development_ref/">Reference</a>
                </li>
    </ul>
                </li>
                <li class="">
                    
    <span class="caption-text">Operators</span>
    <ul class="subnav">
                <li class="toctree-l3">
                    
    <a class="" href="../library_operators/">Operators List</a>
                </li>
                <li class="toctree-l3">
                    
    <a class="" href="../operators/drools_operator/">Drools Operator</a>
                </li>
                <li class="toctree-l3">
                    
    <a class="" href="../operators/python_operator/">Python Operator</a>
                </li>
                <li class="toctree-l3">
                    
    <a class="" href="../operators/PMML_operator/">PMML Operator</a>
                </li>
                <li class="toctree-l3">
                    
    <a class="" href="../operators/tcpinputoperator/">TCP Input Operator</a>
                </li>
                <li class="toctree-l3">
                    
    <a class="" href="../operators/eventhubinput/">Event Hub Input Operator</a>
                </li>
                <li class="toctree-l3">
                    
    <a class="" href="../operators/eventhuboutput/">Event Hub Output Operator</a>
                </li>
                <li class="toctree-l3">
                    
    <a class="" href="../operators/abstracthttpserver/">Abstract HTTP Server Operator</a>
                </li>
                <li class="toctree-l3">
                    
    <a class="" href="../operators/azure_blob/">Azure Blob Storage Operator</a>
                </li>
                <li class="toctree-l3">
                    
    <a class="" href="../operators/aoooperator/">Analytics Output Operator</a>
                </li>
                <li class="toctree-l3">
                    
    <a class="" href="../operators/elasticsearch/">Elasticsearch Output Operator</a>
                </li>
                <li class="toctree-l3">
                    
    <a class="" href="../operators/block_reader/">Block Reader</a>
                </li>
                <li class="toctree-l3">
                    
    <a class="" href="../operators/deduper/">Deduper</a>
                </li>
                <li class="toctree-l3">
                    
    <a class="" href="../operators/dimensions_computation/">Dimension Computation</a>
                </li>
                <li class="toctree-l3">
                    
    <a class="" href="../operators/file_output/">File Output</a>
                </li>
                <li class="toctree-l3">
                    
    <a class="" href="../operators/file_splitter/">File Splitter</a>
                </li>
                <li class="toctree-l3">
                    
    <a class="" href="../operators/hdht/">HDHT</a>
                </li>
                <li class="toctree-l3">
                    
    <a class="" href="../operators/kafkaInputOperator/">Kafka Input</a>
                </li>
                <li class="toctree-l3">
                    
    <a class="" href="../operators/snapshot_server/">Snapshot Server</a>
                </li>
    </ul>
                </li>
                <li class="">
                    
    <a class="" href="../app_data_framework/">App Data Framework</a>
                </li>
                <li class="">
                    
    <a class="" href="../dtgateway_api/">REST API</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">App Templates</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../app-templates/0.10.0/common/import-launch/">Import and Launch App-template</a>
                </li>
                <li class="">
                    
    <a class="" href="../app-templates/0.10.0/common/customize/">Customizing an app-template</a>
                </li>
                <li class="">
                    
    <a class="" href="../app-templates/0.10.0/database-to-database-sync/">Database-to-database-sync</a>
                </li>
                <li class="">
                    
    <a class="" href="../app-templates/0.10.0/hdfs-line-copy/">HDFS-line-copy</a>
                </li>
                <li class="">
                    
    <a class="" href="../app-templates/0.10.0/hdfs-part-file-copy/">HDFS-part-file-copy</a>
                </li>
                <li class="">
                    
    <a class="" href="../app-templates/0.10.0/hdfs-to-hdfs-filter-transform/">HDFS-to-HDFS-filter-transform</a>
                </li>
                <li class="">
                    
    <a class="" href="../app-templates/0.10.0/kafka-to-cassandra-filter-transform/">Kafka-to-Cassandra-Filter-Transform</a>
                </li>
                <li class="">
                    
    <a class="" href="../app-templates/0.10.0/kafka-to-database-sync/">Kafka-to-Database-sync</a>
                </li>
                <li class="">
                    
    <a class="" href="../app-templates/0.10.0/kafka-to-hdfs-filter-transform/">Kafka-to-HDFS-Filter-Transform</a>
                </li>
                <li class="">
                    
    <a class="" href="../app-templates/0.10.0/kafka-to-kafka-filter-transform/">Kafka-to-Kafka-Filter-Transform</a>
                </li>
                <li class="">
                    
    <a class="" href="../app-templates/0.10.0/kinesis-to-redshift/">Kinesis-to-Redshift</a>
                </li>
                <li class="">
                    
    <a class="" href="../app-templates/0.10.0/kinesis-to-s3/">Kinesis-to-S3</a>
                </li>
                <li class="">
                    
    <a class="" href="../app-templates/0.10.0/s3-to-hdfs-sync/">S3-to-HDFS-sync</a>
                </li>
                <li class="">
                    
    <a class="" href="../app-templates/0.10.0/s3-to-redshift/">S3-to-HDFS-Filter-Transform</a>
                </li>
                <li class="">
                    
    <a class="" href="../app-templates/database-to-hdfs/">Database dump to HDFS App</a>
                </li>
                <li class="">
                    
    <a class="" href="../app-templates/database-to-database-sync/">Database to Database Sync App</a>
                </li>
                <li class="">
                    
    <a class="" href="../app-templates/hdfs-sync/">HDFS Sync App</a>
                </li>
                <li class="">
                    
    <a class="" href="../app-templates/hdfs-line-copy/">HDFS to HDFS Line Copy App</a>
                </li>
                <li class="">
                    
    <a class="" href="../app-templates/hdfs-to-kafka-sync/">HDFS to Kafka Sync App</a>
                </li>
                <li class="">
                    
    <a class="" href="../app-templates/hdfs-to-s3-sync/">HDFS to S3 Sync App</a>
                </li>
                <li class="">
                    
    <a class="" href="../app-templates/kafka-to-database-sync/">Kafka to Database Sync App</a>
                </li>
                <li class="">
                    
    <a class="" href="../app-templates/kafka-to-hdfs-filter/">Kafka to HDFS Filter App</a>
                </li>
                <li class="">
                    
    <a class="" href="../app-templates/kafka-to-hdfs-sync/">Kafka to HDFS Sync App</a>
                </li>
                <li class="">
                    
    <a class="" href="../app-templates/kinesis-to-s3/">Kinesis to S3 App</a>
                </li>
                <li class="">
                    
    <a class="" href="../app-templates/s3-to-hdfs-sync/">S3 to HDFS Sync App</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Applications</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../omni_channel_fraud_app/">Omni Channel Fraud Prevention Application</a>
                </li>
                <li class="">
                    
    <a class="" href="../Accounttakeover/">Account Takeover Prevention Application</a>
                </li>
                <li class="">
                    
    <a class="" href="../quickstartlaunchfpa/">Quick Start Guide - Omni-Channel Fraud Prevention Application</a>
                </li>
                <li class="">
                    
    <a class="" href="../quickstartlaunchato/">Quick Start Guide - Account Takeover Prevention Application</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Services</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../cep_workbench/">CEP Workbench</a>
                </li>
                <li class="">
                    
    <a class="" href="../oas_dashboards/">OAS Dashboards</a>
                </li>
                <li class="">
                    
    <a class="" href="../oas/">Online Analytics Service (OAS)</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Platform</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../rts/">RTS</a>
                </li>
                <li class="">
                    
    <a class="" href="../application_configurations/">Application Configurations</a>
                </li>
                <li class="">
                    
    <a class="" href="../dtmanage/">dtManage</a>
                </li>
                <li class="">
                    
    <a class="" href="../dtdashboard/">dtDashboard</a>
                </li>
                <li class="">
                    
    <a class="" href="../dtgateway/">dtGateway</a>
                </li>
                <li class="">
                    
    <a class="" href="../services/">Services</a>
                </li>
                <li class="">
                    
    <a class="" href="../jar_artifacts/">JAR Artifacts</a>
                </li>
                <li class="">
                    
    <a class="" href="../apex/">Apache Apex</a>
                </li>
                <li class="">
                    
    <a class="" href="../apex_malhar/">Apache Apex-Malhar</a>
                </li>
                <li class="">
                    
    <a class="" href="../appbackplane/">Application Backplane</a>
                </li>
                <li class="">
                    
    <a class="" href="../storeandreplay/">Store and Replay Feature</a>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <span class="caption-text">Deployment and Operations</span>
    <ul class="subnav">
                <li class="">
                    
    <a class="" href="../Licensing/">Licensing</a>
                </li>
                <li class="">
                    
    <a class="" href="../installation/">Installation</a>
                </li>
                <li class="">
                    
    <a class="" href="../configuration/">Configuration</a>
                </li>
                <li class="">
                    
    <a class="" href="../dtgateway_security/">Security</a>
                </li>
                <li class="">
                    
    <a class="" href="../dtgateway_systemalerts/">System Alerts</a>
                </li>
                <li class="">
                    
    <a class="" href="../apexcli/">Apex CLI</a>
                </li>
                <li class=" current">
                    
    <a class="current" href="./">Troubleshooting</a>
    <ul class="subnav">
            
    <li class="toctree-l3"><a href="#troubleshooting-guide">Troubleshooting Guide</a></li>
    

    <li class="toctree-l3"><a href="#datatorrent-rts-download">DataTorrent RTS Download</a></li>
    
        <ul>
        
            <li><a class="toctree-l4" href="#where-can-i-download-datatorrent-rts-software">Where can I download DataTorrent RTS software?</a></li>
        
            <li><a class="toctree-l4" href="#what-are-the-dt-licenses-that-can-be-obtained-with-subscription">What are the DT licenses that can be obtained with subscription?</a></li>
        
            <li><a class="toctree-l4" href="#how-do-i-confirm-whether-the-package-has-downloaded-correctly">How do I confirm whether the package has downloaded correctly?</a></li>
        
            <li><a class="toctree-l4" href="#how-do-i-download-the-datatorrent-rts-package-using-cli">How do I download the DataTorrent RTS package using CLI?</a></li>
        
            <li><a class="toctree-l4" href="#what-are-the-prerequisites-of-datatorrent-rts">What are the prerequisites of DataTorrent RTS ?</a></li>
        
            <li><a class="toctree-l4" href="#where-do-i-start-after-downloading-datatorrent-rts">Where do I start after downloading DataTorrent RTS?</a></li>
        
            <li><a class="toctree-l4" href="#what-are-the-supported-hadoop-distribution-by-datatorrent-rts">What are the supported Hadoop distribution by DataTorrent RTS?</a></li>
        
        </ul>
    

    <li class="toctree-l3"><a href="#sandbox">Sandbox</a></li>
    
        <ul>
        
            <li><a class="toctree-l4" href="#what-is-datatorrent-sandbox">What is Datatorrent Sandbox?</a></li>
        
            <li><a class="toctree-l4" href="#where-do-i-get-datatorrent-sandbox-download-link">Where do I get DataTorrent Sandbox download link?</a></li>
        
            <li><a class="toctree-l4" href="#what-are-the-system-requirements-for-sandbox-deployment">What are the system requirements for sandbox deployment?</a></li>
        
            <li><a class="toctree-l4" href="#what-are-the-datatorrent-rts-package-content-details-in-sandbox">What are the DataTorrent RTS package content details in sandbox?</a></li>
        
            <li><a class="toctree-l4" href="#why-does-the-browser-console-on-the-sandbox-state-hdfs-not-ready">Why does the browser console on the sandbox state HDFS Not Ready ?</a></li>
        
        </ul>
    

    <li class="toctree-l3"><a href="#license">License</a></li>
    
        <ul>
        
            <li><a class="toctree-l4" href="#where-can-i-request-new-upgrade-current-license">Where can I request new / upgrade current license?</a></li>
        
        </ul>
    

    <li class="toctree-l3"><a href="#apache-apex">Apache Apex</a></li>
    
        <ul>
        
            <li><a class="toctree-l4" href="#where-can-i-learn-more-about-apache-apex">Where can I learn more about Apache Apex?</a></li>
        
        </ul>
    

    <li class="toctree-l3"><a href="#installation">Installation</a></li>
    
        <ul>
        
            <li><a class="toctree-l4" href="#what-are-the-minimum-requirements-for-hardware">What are the minimum requirements for hardware?</a></li>
        
            <li><a class="toctree-l4" href="#what-happens-if-java-is-not-installed">What happens if java is not installed?</a></li>
        
            <li><a class="toctree-l4" href="#what-happens-if-hadoop-is-not-installed">What happens if Hadoop is not installed?</a></li>
        
            <li><a class="toctree-l4" href="#how-do-i-check-if-hadoop-is-installed-and-running-correctly">How do I check if Hadoop is installed and running correctly?</a></li>
        
            <li><a class="toctree-l4" href="#what-happens-if-the-downloaded-file-is-corrupted">What happens if the downloaded file is corrupted?</a></li>
        
            <li><a class="toctree-l4" href="#why-do-i-see-the-following-permissions-errors-during-installation">Why do I see the following permissions errors during installation?</a></li>
        
        </ul>
    

    <li class="toctree-l3"><a href="#upgrade">Upgrade</a></li>
    
        <ul>
        
            <li><a class="toctree-l4" href="#license-agent-errors-cause-problems-during-upgrade-from-datatorrent-rts-20-to-30">License agent errors cause problems during upgrade from DataTorrent RTS 2.0 to 3.0.</a></li>
        
        </ul>
    

    <li class="toctree-l3"><a href="#services">Services</a></li>
    
        <ul>
        
            <li><a class="toctree-l4" href="#online-analytics-service-oas">Online Analytics Service (OAS)</a></li>
        
        </ul>
    

    <li class="toctree-l3"><a href="#configuration">Configuration</a></li>
    
        <ul>
        
            <li><a class="toctree-l4" href="#configuring-memory">Configuring Memory</a></li>
        
        </ul>
    

    <li class="toctree-l3"><a href="#development">Development</a></li>
    
        <ul>
        
            <li><a class="toctree-l4" href="#hadoop-dependencies-conflicts">Hadoop dependencies conflicts</a></li>
        
            <li><a class="toctree-l4" href="#serialization-considerations">Serialization considerations</a></li>
        
        </ul>
    

    <li class="toctree-l3"><a href="#debugging">Debugging</a></li>
    
        <ul>
        
            <li><a class="toctree-l4" href="#how-to-remotely-debug-the-gateway-service">How to remotely debug the gateway service?</a></li>
        
            <li><a class="toctree-l4" href="#how-to-setup-debug-level-while-running-an-application">How to setup DEBUG level while running an application?</a></li>
        
            <li><a class="toctree-l4" href="#my-gateway-is-throwing-the-following-exception">My gateway is throwing the following exception.</a></li>
        
            <li><a class="toctree-l4" href="#when-apex-is-running-in-a-secure-mode-yarn-logs-get-flooded-with-several-thousand-messages-per-second">When Apex is running in a secure mode, YARN logs get flooded with several thousand messages per second.</a></li>
        
            <li><a class="toctree-l4" href="#application-throws-kryo-exception">Application throws Kryo exception.</a></li>
        
        </ul>
    

    <li class="toctree-l3"><a href="#log-analysis">Log analysis</a></li>
    
        <ul>
        
            <li><a class="toctree-l4" href="#how-to-check-stram-logs">How to check STRAM logs?</a></li>
        
            <li><a class="toctree-l4" href="#how-to-check-application-logs">How to check application logs?</a></li>
        
            <li><a class="toctree-l4" href="#how-to-check-killed-operators-state">How to check killed operator’s state?</a></li>
        
            <li><a class="toctree-l4" href="#how-to-search-for-a-specific-application-or-container">How to search for a specific application or container?</a></li>
        
            <li><a class="toctree-l4" href="#how-do-i-search-within-logs">How do I search within logs?</a></li>
        
        </ul>
    

    <li class="toctree-l3"><a href="#launching-applications">Launching Applications</a></li>
    
        <ul>
        
            <li><a class="toctree-l4" href="#application-goes-from-accepted-state-to-finishedfailed-state">Application goes from accepted state to Finished(FAILED) state.</a></li>
        
            <li><a class="toctree-l4" href="#constraintviolationexception-during-application-launch">ConstraintViolationException during application launch.</a></li>
        
        </ul>
    

    <li class="toctree-l3"><a href="#events">Events</a></li>
    
        <ul>
        
            <li><a class="toctree-l4" href="#how-to-check-container-failures">How to check container failures?</a></li>
        
            <li><a class="toctree-l4" href="#how-to-search-within-events">How to search within events?</a></li>
        
            <li><a class="toctree-l4" href="#what-is-the-difference-between-tail-mode-and-range-mode">What is the difference between tail mode and range mode?</a></li>
        
            <li><a class="toctree-l4" href="#what-is-following-button-in-the-events-pane">What is “following” button in the events pane?</a></li>
        
            <li><a class="toctree-l4" href="#how-do-i-get-a-heap-dump-when-a-container-gets-an-outofmemoryerror">How do I get a heap dump when a container gets an OutOfMemoryError?</a></li>
        
        </ul>
    

    <li class="toctree-l3"><a href="#support">Support</a></li>
    
        <ul>
        
            <li><a class="toctree-l4" href="#do-you-need-help">Do you need help?</a></li>
        
        </ul>
    

    </ul>
                </li>
    </ul>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../release_notes/">Release Notes</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../glossary/">Glossary</a>
	    </li>
          
            <li class="toctree-l1">
		
    <a class="" href="../additional_docs/">Resources</a>
	    </li>
          
        </ul>
      </div>
      &nbsp;
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" role="navigation" aria-label="top navigation">
        <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
        <a href="..">DataTorrent Documentation</a>
      </nav>

      
      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="breadcrumbs navigation">
  <ul class="wy-breadcrumbs">
    <li><a href="..">Docs</a> &raquo;</li>
    
      
        
          <li>Deployment and Operations &raquo;</li>
        
      
    
    <li>Troubleshooting</li>
    <li class="wy-breadcrumbs-aside">
      
    </li>
  </ul>
  <hr/>
</div>
          <div role="main">
            <div class="section">
              
                <h1 id="troubleshooting-guide">Troubleshooting Guide</h1>
<h1 id="datatorrent-rts-download">DataTorrent RTS Download</h1>
<h2 id="where-can-i-download-datatorrent-rts-software">Where can I download DataTorrent RTS software?</h2>
<p>DataTorrent RTS software can be downloaded from <a href="https://www.datatorrent.com/download">https://www.datatorrent.com/download/</a></p>
<p>The following deployment options are available for downloading DataTorrent RTS:
- <strong>DataTorrent RTS - Sandbox Appliance</strong>
- <strong>DataTorrent RTS - Installable Binary</strong>
- <strong>DataTorrent RTS - Cloud Instance</strong> </p>
<h2 id="what-are-the-dt-licenses-that-can-be-obtained-with-subscription">What are the DT licenses that can be obtained with subscription?</h2>
<p>Refer to <a href="http://docs.datatorrent.com/Licensing/#datatorrent-licensing">http://docs.datatorrent.com/Licensing/#datatorrent-licensing</a></p>
<h2 id="how-do-i-confirm-whether-the-package-has-downloaded-correctly">How do I confirm whether the package has downloaded correctly?</h2>
<p>You can verify the downloaded DataTorrent RTS package by comparing with
MD5 sum. The command to get md5 sum of the downloaded package:</p>
<pre><code># md5sum &lt;DT_RTS_Package&gt;
</code></pre>
<p>Compare the result with MD5 sum posted on the product download page.</p>
<h2 id="how-do-i-download-the-datatorrent-rts-package-using-cli">How do I download the DataTorrent RTS package using CLI?</h2>
<p>Use following curl command to download DataTorrent RTS package:</p>
<pre><code>curl -LSO &lt;DT_RTS_download_link&gt;
</code></pre>
<p>It is recommended to use <code>curl</code> instead of <code>wget</code> which lacks chunked transfer encoding support and which can potentially result in corrupted downloads.</p>
<h2 id="what-are-the-prerequisites-of-datatorrent-rts">What are the prerequisites of DataTorrent RTS ?</h2>
<p>DataTorrent RTS platform has following Hadoop cluster requirements:</p>
<ul>
<li>Operating system supported by Hadoop distribution</li>
<li>Hadoop (2.6 or above) cluster with YARN, HDFS configured. Make sure
    hadoop executable is available in the PATH variable.</li>
<li>Java 7 or 8 as supported by Hadoop distribution</li>
<li>Minimum of 8G RAM available on the Hadoop cluster</li>
<li>Permissions to create HDFS directory for DataTorrent user</li>
<li>Google Chrome or Safari to access dtManage (DataTorrent UI
    console)</li>
</ul>
<h2 id="where-do-i-start-after-downloading-datatorrent-rts">Where do I start after downloading DataTorrent RTS?</h2>
<ul>
<li>After successful download of DataTorrent RTS, make sure all prerequisites are satisfied.</li>
<li>You must install DataTorrent RTS on the Hadoop cluster using the downloaded installer. Refer to <a href="../installation/">installation guide</a></li>
<li>Once installed, you are prompted to proceed to dtManage, the DataTorrent management console, where you can launch and manage applications.</li>
</ul>
<h2 id="what-are-the-supported-hadoop-distribution-by-datatorrent-rts">What are the supported Hadoop distribution by DataTorrent RTS?</h2>
<p>DataTorrent RTS is a Hadoop 2.x native application and is fully
integrated with YARN and HDFS providing tight integration with any
Apache Hadoop 2.x based distribution.</p>
<table>
<col width="50%" />
<col width="50%" />
<tbody>
<tr class="odd">
<td align="left"><p>Hadoop Distribution</p></td>
<td align="left"><p>Supported Version</p></td>
</tr>
<tr class="even">
<td align="left"><p>Amazon EMR</p></td>
<td align="left"><p>Hadoop 2.4 and higher</p></td>
</tr>
<tr class="odd">
<td align="left"><p>Apache Hadoop</p></td>
<td align="left"><p>Hadoop 2.2 and higher</p></td>
</tr>
<tr class="even">
<td align="left"><p>Cloudera</p></td>
<td align="left"><p>CDH 5.0 and higher</p></td>
</tr>
<tr class="odd">
<td align="left"><p>Hortonworks</p></td>
<td align="left"><p>HDP 2.0 and higher</p></td>
</tr>
<tr class="even">
<td align="left"><p>MapR</p></td>
<td align="left"><p>4.0 and higher</p></td>
</tr>
<tr class="odd">
<td align="left"><p>Microsoft</p></td>
<td align="left"><p>HDInsight</p></td>
</tr>
<tr class="even">
<td align="left"><p>Pivotal</p></td>
<td align="left"><p>2.1 and higher</p></td>
</tr>
</tbody>
</table>

<h1 id="sandbox">Sandbox</h1>
<h2 id="what-is-datatorrent-sandbox">What is Datatorrent Sandbox?</h2>
<p>DataTorrent Sandbox is a deployment option that provides a quick and simple way to experience DataTorrent RTS without setting up and managing a complete Hadoop cluster. The latest version of DataTorrent RTS is pre-installed on it along with all the Hadoop services required to launch and run the included demo applications. See also http://docs.datatorrent.com/sandbox/</p>
<h2 id="where-do-i-get-datatorrent-sandbox-download-link">Where do I get DataTorrent Sandbox download link?</h2>
<p>Sandbox can be downloaded from <a href="https://www.datatorrent.com/download/">datatorrent.com/download</a></p>
<h2 id="what-are-the-system-requirements-for-sandbox-deployment">What are the system requirements for sandbox deployment?</h2>
<p>The system requirements for Sandbox deployment are as follows:
-  <a href="https://www.virtualbox.org/">Oracle VirtualBox</a> 4.3 or greater installed.
-  6GB RAM or greater available for Sandbox VM.</p>
<h2 id="what-are-the-datatorrent-rts-package-content-details-in-sandbox">What are the DataTorrent RTS package content details in sandbox?</h2>
<ul>
<li>Ubuntu 14.0.4 </li>
<li>Apache Hadoop 2.6 </li>
<li>Apache Apex Core 3.7.0</li>
<li>DataTorrent RTS 3.10.0</li>
</ul>
<h2 id="why-does-the-browser-console-on-the-sandbox-state-hdfs-not-ready">Why does the browser console on the sandbox state <code>HDFS Not Ready</code> ?</h2>
<p>The HDFS services take a few minutes to start. The console needs all those services to be up and running and until that occurs, it displays this warning. If the normal console does not appear after a few minutes, run the <code>jps</code> command to see which services may <em>not</em> be running, for example:</p>
<pre><code class="shell">dtadmin@dtbox:~/tmp$ jps
1407 DTGateway
4145 Jps
2830 NodeManager
3059 ResourceManager
2650 NameNode
</code></pre>

<p>Here we see that the <code>DataNode</code> is not running. In this case, stop all HDFS services (using, for example the script shown in the
<a href="http://docs.datatorrent.com/sandbox/">sandbox page</a>. Then, remove everything under these directories:</p>
<pre><code>/sfw/hadoop/shared/data/hdfs/datanode/current
/sfw/hadoop/shared/data/hdfs/namenode/current
</code></pre>
<p>Now reformat HDFS with <code>hdfs namenode -format</code> and finally restart all the HDFS services.</p>
<p>If all the services are running and the normal console still does not appear, run following commands:</p>
<pre><code class="shell">hdfs dfsadmin -safemode leave
hdfs fsck -delete
</code></pre>

<p>If HDFS detects that some files are corrupted (perhaps due to an earlier improper shutdown), it will not exit the initial safemode automatically; the commands above exit safemode manually and delete the corrupted files.</p>
<h1 id="license">License</h1>
<h2 id="where-can-i-request-new-upgrade-current-license">Where can I request new / upgrade current license?</h2>
<p>Follow the instructions at <a href="https://www.datatorrent.com/license-upgrade/">License Upgrade</a></p>
<h1 id="apache-apex">Apache Apex</h1>
<h2 id="where-can-i-learn-more-about-apache-apex">Where can I learn more about Apache Apex?</h2>
<p>You can refer Apex page for more details: <a href="http://apex.apache.org">Apache Apex</a></p>
<h1 id="installation">Installation</h1>
<h2 id="what-are-the-minimum-requirements-for-hardware">What are the minimum requirements for hardware?</h2>
<p>Minimum of 8G RAM is required on the Hadoop cluster.</p>
<h2 id="what-happens-if-java-is-not-installed">What happens if java is not installed?</h2>
<p>The following message is displayed when Java is not available on the system:</p>
<pre><code>Error: java executable not found. Please ensure java
or hadoop are installed and available in PATH environment variable
before proceeding with this installation.
</code></pre>
<p>Install Java 7 from package manager of Linux Distribution and run the installer again.</p>
<h2 id="what-happens-if-hadoop-is-not-installed">What happens if Hadoop is not installed?</h2>
<p>Installation will be successful, however Hadoop Configuration page in dtManage (e.g. http://localhost:9090) will expect Hadoop binary (/usr/bin/hadoop) &amp; DFS location.</p>
<p><img alt="HadoopConfiguration.png" src="../images/troubleshooting/image02.png" /></p>
<p>Install Hadoop and update the configuration parameters above.</p>
<h2 id="how-do-i-check-if-hadoop-is-installed-and-running-correctly">How do I check if Hadoop is installed and running correctly?</h2>
<p>The following commands can be used to confirm the installed Hadoop version and to check if Hadoop services are running.</p>
<pre><code>$ hadoop version

Hadoop 2.4.0
Subversion [http://svn.apache.org/repos/asf/hadoop/common](http://svn.apache.org/repos/asf/hadoop/common) -r
1583262
Compiled by jenkins on 2014-03-31T08:29Z
Compiled with protoc 2.5.0
From source with checksum 375b2832a6641759c6eaf6e3e998147
This command was run using
/usr/local/hadoop/share/hadoop/common/hadoop-common-2.4.0.jar

$ jps

10211 NameNode
10772 ResourceManager
10427 DataNode
14691 Jps
10995 NodeManager
</code></pre>
<h2 id="what-happens-if-the-downloaded-file-is-corrupted">What happens if the downloaded file is corrupted?</h2>
<p>MD5 checksum will result in the following error:</p>
<pre><code>“Verifying archive integrity...Error in MD5 checksums: &lt;MD5 checksum&gt; is different from &lt;MD5 checksum&gt;”.
</code></pre>
<p>Downloaded installer could be corrupted.  Try downloading the installer again.  </p>
<p><strong>Note:</strong> If using command line, use <code>curl</code> instead of <code>wget</code>.</p>
<h2 id="why-do-i-see-the-following-permissions-errors-during-installation">Why do I see the following permissions errors during installation?</h2>
<p><img alt="Permissions Error" src="../images/troubleshooting/image01.png" /></p>
<p>This happens when the specified directory does not exist, and the installation user do not have the permissions to create it.  Following commands can be executed by the user, with the required privileges, to resolve this issue:</p>
<pre><code>$ hadoop dfs -ls /user/&lt;USER&gt;/datatorrent
$ hadoop dfs -mkdir /user/&lt;USER&gt;/datatorrent  
$ hadoop dfs -chown &lt;USER&gt; /user/&lt;USER&gt;/datatorrent
</code></pre>
<h1 id="upgrade">Upgrade</h1>
<h2 id="license-agent-errors-cause-problems-during-upgrade-from-datatorrent-rts-20-to-30">License agent errors cause problems during upgrade from DataTorrent RTS 2.0 to 3.0.</h2>
<p>If your applications are being launched continuously, or you are unable to launch apps due to licensing errors, try uninstalling and re-installing DataTorrent RTS.  See <a href="../installation/">installation guide</a> for details.</p>
<h1 id="services">Services</h1>
<h2 id="online-analytics-service-oas">Online Analytics Service (OAS)</h2>
<h3 id="handling-high-ingestion-rate-in-oas">Handling High Ingestion Rate in OAS</h3>
<p>Usually, OAS consumes the Kafka topic data as soon as it is available from upstream. However, if it cannot cope with the incoming rate, there can be failures in the <strong>Input</strong> operator. 
To avoid such issues, the following approaches are suggested:</p>
<ul>
<li><strong>OlapParser Operator partitioning</strong></li>
</ul>
<p>OlapParser operator can be partitioned, if the ingestion rate is very high. For example,  for creating 4 partitions, the property      <strong><em>dt.operator.OlapParser.attr.PARTITIONER</em></strong> can be used with value as <strong><em>com.datatorrent.common.partitioner.StatelessPartitioner:4</em></strong></p>
<ul>
<li><strong>Increase Retention period for kafka topic</strong></li>
</ul>
<p>If OAS is overloaded and not processing the data at the same rate as upstream, the retention period for the kafka topic can be increased. This gives sufficient time for OAS to process all the topic data.</p>
<ul>
<li><strong>Specify 'auto.offset.reset' consumer property</strong></li>
</ul>
<p>There can be cases where OAS is unable to keep pace with the upstream and the older data in Kafka topic gets expired because of  the  retention policy that is set before getting processed by OAS. In such cases the OAS <strong>Input</strong> operator may fail. To avoid this failure, the consumer property <strong><em>dt.operator.Input.prop.consumerProps(auto.offset.reset)</em></strong> can be set in OAS with value as <strong><em>earliest</em></strong>. With this property, in case of older topic data expiry, the offset used for reading the data is <strong><em>earliest</em></strong>  that is whichever oldest offset that is currently available with the topic. This avoids the Input operator failure but also involves some loss of data.
<strong>Caution</strong>: This is not the recommended approach,  as it may result in data loss without any notification.</p>
<h1 id="configuration">Configuration</h1>
<h2 id="configuring-memory">Configuring Memory</h2>
<h3 id="configuring-operator-memory">Configuring Operator Memory</h3>
<p>Operator memory for an operator can be configured in one of the following two ways:</p>
<p>1 Using the same default values for all the operators: </p>
<pre><code>&lt;property&gt;
  &lt;name&gt;dt.application.&lt;APPLICATION_NAME&gt;.operator.*.attr.MEMORY_MB&lt;/name&gt;
  &lt;value&gt;2048&lt;/value&gt;
&lt;/property&gt;
</code></pre>
<p>This will set 2GB as the size of all the operators in the given application.</p>
<p>2 Setting specific value for an operator: 
  Following example will set 8 GB as the operator memory for operator <code>Op</code>.</p>
<pre><code>&lt;property&gt;
  &lt;name&gt;dt.application.&lt;APPLICATION_NAME&gt;.operator.Op.attr.MEMORY_MB&lt;/name&gt;
  &lt;value&gt;8192&lt;/value&gt;
&lt;/property&gt;
</code></pre>
<p>The memory required by an operator should be based on the maximum data that the operator will store in-memory for all the fields: both transient and non-transient. Default value for this attribute is 1024 MB.</p>
<h3 id="configuring-buffer-server-memory">Configuring Buffer Server Memory</h3>
<p>There is a buffer server in each container hosting an operator with an output port connected to an input port outside the container. The buffer server memory of a container can be controlled by BUFFER_MEMORY_MB. This can be configured in one of the following ways:</p>
<p>1 Using the same default values for all the output ports of all the operators</p>
<pre><code>&lt;property&gt;
  &lt;name&gt;dt.application.&lt;APPLICATION_NAME&gt;.operator.*.port.*.attr.BUFFER_MEMORY_MB&lt;/name&gt;
  &lt;value&gt;128&lt;/value&gt;
&lt;/property&gt;
</code></pre>
<p>This sets 128 MB as the buffer memory for all the output ports of all the operators.</p>
<p>2 Setting a specific value for a specific output port of a specific operator: 
  The following example sets 1 GB as buffer memory for output port <code>p</code> of an operator <code>Op</code>:</p>
<pre><code>&lt;property&gt;
  &lt;name&gt;dt.application.&lt;APPLICATION_NAME&gt;.operator.Op.port.p.attr.BUFFER_MEMORY_MB&lt;/name&gt;
  &lt;value&gt;1024&lt;/value&gt;
&lt;/property&gt;
</code></pre>
<p>Default value for this attribute is 512 MB</p>
<h3 id="calculating-container-memory">Calculating Container memory</h3>
<p>Following formula is used to calculate the container memory.</p>
<pre><code>Container Memory = Sum of MEMORY_MB of All the operators in the container+ Sum of BUFFER_MEMORY_MB of all the output ports that have a sink in a different container.
</code></pre>
<p>Sometimes the memory allocated to the container is not the same as calculated by the above formula. This is because the actual container memory allocated by RM has to lie between</p>
<pre><code>[yarn.scheduler.minimum-allocation-mb, yarn.scheduler.maximum-allocation-mb]
</code></pre>
<p>These values can be found in yarn configuration.</p>
<h3 id="configuring-application-master-memory">Configuring Application Master Memory</h3>
<p>Application Master memory can be configured using MASTER_MEMORY_MB attribute. 
The following example sets 4 GB as the memory for Application Master:</p>
<pre><code>&lt;property&gt;
  &lt;name&gt;dt.application.&lt;APPLICATION_NAME&gt;.attr.MASTER_MEMORY_MB&lt;/name&gt;
  &lt;value&gt;4096&lt;/value&gt;
&lt;/property&gt;
</code></pre>
<p>Default value for this attribute is 1024 MB. You may need to increase this value if you are running a big application that has large number of containers</p>
<h1 id="development">Development</h1>
<h2 id="hadoop-dependencies-conflicts">Hadoop dependencies conflicts</h2>
<p>You must ensure that the Hadoop JARs are not bundled with the application package, else they may conflict with the versions available in the Hadoop classpath. Here are some ways to exclude Hadoop dependencies from the application package:</p>
<ol>
<li>
<p>If your application is directly dependent on the Hadoop jars, make sure that the scope of the dependency is <code>provided</code>. For example,  if your application is dependent on hadoop-common, you can add the dependency in pom.xml as follows:</p>
<pre><code>&lt;dependency&gt;
  &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;
  &lt;artifactId&gt;hadoop-common&lt;/artifactId&gt;
  &lt;version&gt;2.2.0&lt;/version&gt;
  &lt;scope&gt;provided&lt;/scope&gt;
&lt;/dependency&gt;
</code></pre>
</li>
<li>
<p>If your application has transitive dependency on Hadoop jars, make sure that Hadoop jars are excluded from the transitive dependency and added back as application dependency with the provided scope as mentioned above. Exclusions in pom.xml can be set as follows:</p>
<pre><code>&lt;dependency&gt;
  &lt;groupId&gt;&lt;/groupId&gt;
  &lt;artifactId&gt;&lt;/artifactId&gt;
  &lt;version&gt;&lt;/version&gt;
  &lt;exclusions&gt;
    &lt;exclusion&gt;
      &lt;groupId&gt;org.apache.hadoop&lt;/groupId&gt;
      &lt;artifactId&gt;*&lt;/artifactId&gt;
    &lt;/exclusion&gt;
  &lt;/exclusions&gt;
&lt;/dependency&gt;
</code></pre>
</li>
</ol>
<h2 id="serialization-considerations">Serialization considerations</h2>
<p>An Apex application needs to satisfy serializability requirements on operators and tuples as follows:</p>
<h3 id="operators">Operators</h3>
<p>After an application is launched, the DAG is serialized using a combination of
<a href="https://docs.oracle.com/javase/8/docs/platform/serialization/spec/serialTOC.html">Java Serialization</a> and
<a href="https://github.com/EsotericSoftware/kryo/blob/master/README.md">Kryo</a> and then the DAG is
transferred over the network from the launching node to the application master node.</p>
<p>Checkpointing also involves serializing and persisting an operator state to a store and deserializing 
from the store in case of recovery. The platform uses Kryo serialization in this case. Kryo imposes
additional requirements on an operator Java class to be deserializable. For more details check out
this <a href="https://github.com/EsotericSoftware/kryo/blob/master/README.md#object-creation">page</a>.</p>
<h3 id="tuples">Tuples</h3>
<p>Tuples are serialized (and deserialized) according to the specified stream codec when transmitted between Yarn containers.
When no stream codec is specified, Apex uses the default stream codec that relies on the 
<a href="https://github.com/EsotericSoftware/kryo/blob/master/README.md">Kryo</a> serialization library to
serialize and deserialize tuples. A custom stream codec can be specified to use a different serialization
framework.</p>
<p>Thread and container local streams do not use a stream codec, hence tuples don't need to be serializable in such cases.</p>
<h3 id="troubleshooting-serialization-issues">Troubleshooting serialization issues</h3>
<p>There is no guaranteed way to uncover serialization issues in your code. An operator may emit a problematic tuple
only in very rare and hard to reproduce conditions while testing. Kryo deserialization problem in an operator will 
not be uncovered until the recovery time, and at that point it is most likely too late. It is recommended to unit
test an operator's ability to restore itself properly similar to this 
<a href="https://github.com/apache/apex-malhar/blob/master/library/src/test/java/com/datatorrent/lib/io/fs/AbstractFileOutputOperatorTest.java">example</a></p>
<p>To exercise tuple serialization, run your application in 
<a href="http://apex.apache.org/docs/apex/application_development/#local-mode">local mode</a> that could uncover many tuple
serialization problems. Use the <a href="http://apex.apache.org/docs/apex/apex_cli/">ApexCLI</a> to launch your application with
the <code>-local</code> option to run it in local mode. The application will fail at a point when the platform is unable to serialize
or deserialize a tuple,and the relevant exception will be logged on the console or a log file as described in the 
<a href="#application-throwing-following-kryo-exception">Kryo exception</a> section. Check out that section further for
hints about troubleshooting serialization issues.</p>
<h3 id="transient-members">Transient members</h3>
<p>Certain data members of an operator do not need to be serialized or deserialized during deployment or 
checkpointing/recovery because they are <a href="http://docs.oracle.com/javase/specs/jls/se7/html/jls-8.html#jls-8.3.1.3">transient</a>
in nature and do not represent stateful data. Developers should judiciously use the 
<a href="http://docs.oracle.com/javase/specs/jls/se7/html/jls-8.html#jls-8.3.1.3">transient</a> keyword for declaring
such non-stateful members of operators (or members of objects that are indirectly members of operators) 
so that the platform skips serialization of such members and serialization/deserialization errors are 
minimized. Transient members are further described in the context of the operator life-cycle 
<a href="http://apex.apache.org/docs/apex/operator_development/#setup-call">here</a>. Typical examples of
transient data members are database or network connection objects which need to be 
initialized before they are used in a process, so they are never persisted across process invocations.</p>
<h1 id="debugging">Debugging</h1>
<h2 id="how-to-remotely-debug-the-gateway-service">How to remotely debug the gateway service?</h2>
<p>Update Hadoop OPTS variable by running the following:</p>
<pre><code>export HADOOP_OPTS="-agentlib:jdwp=transport=dt_socket,server=y,suspend=y,address=5432 $HADOOP_OPTS"
</code></pre>
<h2 id="how-to-setup-debug-level-while-running-an-application">How to setup DEBUG level while running an application?</h2>
<p>Add the following property to your properties file:</p>
<pre><code>&lt;property&gt;
  &lt;name&gt;dt.application.&lt;APP-NAME&gt;.attr.DEBUG&lt;/name&gt;
  &lt;value&gt;true&lt;/value&gt;
&lt;/property&gt;
</code></pre>
<h2 id="my-gateway-is-throwing-the-following-exception">My gateway is throwing the following exception.</h2>
<pre><code>  ERROR YARN Resource Manager has problem: java.net.ConnectException: Call From myexample.com/192.168.3.21 to 0.0.0.0:8032 failed on connection
  exception: java.net.ConnectException: Connection refused; For more  details see:[http://wiki.apache.org/hadoop/ConnectionRefused](http://wiki.apache.org/hadoop/ConnectionRefused) at
  sun.reflect.GeneratedConstructorAccessor27.newInstance(Unknown Source)
  at sun.reflect.DelegatingConstructorAccessorImpl.newInstance(DelegatingConstructorAccessorImpl.java:45)
  ...
</code></pre>
<p>Check if the host where gateway is running has <strong>yarn-site.xml</strong> file. You need to have all Hadoop configuration files accessible to dtGateway for it to run successfully.</p>
<h2 id="when-apex-is-running-in-a-secure-mode-yarn-logs-get-flooded-with-several-thousand-messages-per-second">When Apex is running in a secure mode, YARN logs get flooded with several thousand messages per second.</h2>
<p>Ensure that the kerberos principal user name has an account with the same user ID on the cluster nodes.</p>
<h2 id="application-throws-kryo-exception">Application throws Kryo exception.</h2>
<p>Application throws the following Kryo exception:</p>
<pre><code>  com.esotericsoftware.kryo.KryoException: Class cannot be created (missing no-arg constructor):
</code></pre>
<p>This implies that Kryo is unable to deserialize the object because the type is missing default constructor. There are couple of ways to address this exception.</p>
<ol>
<li>Add default constructor to the type in question.</li>
<li>
<p>Using <a href="https://github.com/EsotericSoftware/kryo#serializers">custom serializer</a> for the type in question. Some existing alternative serializers can be found at <a href="https://github.com/magro/kryo-serializers">https://github.com/magro/kryo-serializers</a>. A custom serializer can be used as follows:</p>
<p>2.1 Using Kryo's @FieldSerializer.Bind annotation for the field causing the exception. Here is how to bind custom serializer.</p>
<pre><code>@FieldSerializer.Bind(CustomSerializer.class)
SomeType someType
</code></pre>
<p>Kryo will use this CustomSerializer to serialize and deserialize type SomeType. If SomeType is a Map or Collection, there are some special annotations @BindMap and @BindCollection; See <a href="https://github.com/EsotericSoftware/kryo">here</a>.</p>
<p>2.2 Using the @DefaultSerializer annotation on the class, for example:</p>
<pre><code>@DefaultSerializer(JavaSerializer.class)
public class SomeClass ...
</code></pre>
<p>2.3 Using custom serializer with stream codec. You need to define custom stream codec and attach this custom codec to the input port that is expecting the type in question. Following is an example of creating custom stream codec:</p>
<pre><code>import java.io.IOException;
import java.io.ObjectInputStream;
import java.util.UUID;
import com.esotericsoftware.kryo.Kryo;

public class CustomSerializableStreamCodec&lt;T&gt; extends com.datatorrent.lib.codec.KryoSerializableStreamCodec&lt;T&gt;
{
    private void readObject(ObjectInputStream in) throws IOException, ClassNotFoundException
    {
        in.defaultReadObject();
        this.kryo = new Kryo();
        this.kryo.setClassLoader(Thread.currentThread().getContextClassLoader());
        this.kryo.register(SomeType.class, new CustomSerializer()); // Register the types along with custom serializers
    }

    private static final long serialVersionUID = 201411031405L;
}
</code></pre>
<p>Suppose there is an Operator <code>CustomOperator</code> with an input port <code>input</code> that expects type SomeType. Following example shows how to use the above defined custom stream codec:</p>
<pre><code>CustomOperator op = dag.addOperator("CustomOperator", new CustomOperator());
CustomSerializableStreamCodec&lt;SomeType&gt; codec = new CustomSerializableStreamCodec&lt;SomeType&gt;();
dag.setInputPortAttribute(op.input, Context.PortContext.STREAM_CODEC, codec);
</code></pre>
<p>This works only when the type is passed between different operators. If the type is part of the operator state, use one of the above two ways. </p>
</li>
</ol>
<h1 id="log-analysis">Log analysis</h1>
<p>There are multiple ways to adjust logging levels.  For details see <a href="../configuration/#application-logging">configuration guide</a>.</p>
<h2 id="how-to-check-stram-logs">How to check STRAM logs?</h2>
<p>You can get STRAM logs by retrieving YARN logs from command line, or by using dtManage web interface.  </p>
<p>In dtManage console, select first container from the Containers List in the Physical application view.  The first container is numbered 000001. Then click the logs dropdown and select the log you want to view.  </p>
<p>Alternatively, the following command can retrieve all application logs, where the first container includes the STRAM log.</p>
<pre><code>yarn logs -applicationId &lt;applicationId&gt;
</code></pre>
<h2 id="how-to-check-application-logs">How to check application logs?</h2>
<p>On the dtconsole, select a container from the Containers List widget (default location of this widget is in the <strong>physical</strong> dashboard). Then click the logs dropdown and select the log you want to view.</p>
<p><img alt="console-log-viewing.gif" src="../images/troubleshooting/image00.gif" /></p>
<h2 id="how-to-check-killed-operators-state">How to check killed operator’s state?</h2>
<p>On dtconsole, click the <strong>retrieve killed</strong> button of the container List. Containers List widget’s default location is on the <strong>physical</strong> dashboard. Then select the appropriate container of the killed operator and check the state.</p>
<p><img alt="RetrieveKilled.gif" src="../images/troubleshooting/image03.gif" /></p>
<h2 id="how-to-search-for-a-specific-application-or-container">How to search for a specific application or container?</h2>
<p>In applications or containers table there is search text box. You can type in the application name or the container number to locate a specific application or container.</p>
<h2 id="how-do-i-search-within-logs">How do I search within logs?</h2>
<ol>
<li>Navigate to the logs page. </li>
<li>Download log file to search using your preferred editor. </li>
<li>use <strong>grep</strong> option and provide the search range <strong>within specified range</strong> or <strong>over entire log</strong>.</li>
</ol>
<h1 id="launching-applications">Launching Applications</h1>
<h2 id="application-goes-from-accepted-state-to-finishedfailed-state">Application goes from accepted state to Finished(FAILED) state.</h2>
<p>Check if your application name conflicts with any of the already running applications in your cluster. Apex does not allow two applications with the same name to run simultaneously.
Your STRAM logs will have following error:<br />
<em>Forced shutdown due to Application master failed due to application
\&lt;appId> with duplicate application name \&lt;appName> by the same user
\&lt;user name> is already started.</em> </p>
<h2 id="constraintviolationexception-during-application-launch">ConstraintViolationException during application launch.</h2>
<p>Check if all @NotNull properties of application are set. Apex operator properties are meant to configure parameter to operators. Some of the properties are must have, marked as @NotNull, to use an operator. If you don’t set any of such @NotNull properties application launch will fail and stram will throw ConstraintViolationException.    </p>
<h1 id="events">Events</h1>
<h2 id="how-to-check-container-failures">How to check container failures?</h2>
<p>In StramEvents list (default location of this widget is in the <strong>logical</strong> dashboard), look for event <strong>StopContainer</strong>. Click the <strong>details</strong> button corresponding to the event to get details of the container failure.</p>
<h2 id="how-to-search-within-events">How to search within events?</h2>
<p>You can search events in specified time range. Select <strong>range</strong> mode in StramEvents widget. Then select from and to timestamp and hit the search button.</p>
<h2 id="what-is-the-difference-between-tail-mode-and-range-mode">What is the difference between tail mode and range mode?</h2>
<p><strong>tail</strong> mode allows you to see events as they come in whereas <strong>range</strong> mode allows you to search for events by time range.</p>
<h2 id="what-is-following-button-in-the-events-pane">What is “following” button in the events pane?</h2>
<p>When we enable <strong>following</strong>” button the stram events list, it will automatically scroll to the bottom whenever new events come in.</p>
<h2 id="how-do-i-get-a-heap-dump-when-a-container-gets-an-outofmemoryerror">How do I get a heap dump when a container gets an OutOfMemoryError?</h2>
<p>The JVM has a special option for triggering a heap dump when an Out Of Memory error occurs, as well an associated option for specifying the name of the file to contain the dump namely <code>-XX:+HeapDumpOnOutOfMemoryError</code> and <code>-XX:HeapDumpPath=/tmp/op.heapdump</code>.
To add them to a specific operator, use this stanza in your configuration file with <code>&lt;OPERATOR_NAME&gt;</code> replaced by the actual name of an operator:</p>
<pre><code>    &lt;property&gt;
      &lt;name&gt;dt.operator.&lt;OPERATOR_NAME&gt;.attr.JVM_OPTIONS&lt;/name&gt;
      &lt;value&gt;-XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp/op.heapdump&lt;/value&gt;
    &lt;/property&gt;
</code></pre>
<p>To add them to all your containers, add this stanza to your configuration file:</p>
<pre><code>    &lt;property&gt;
      &lt;name&gt;dt.attr.CONTAINER_JVM_OPTIONS&lt;/name&gt;
      &lt;value&gt;-XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=/tmp/op.heapdump&lt;/value&gt;
    &lt;/property&gt;
</code></pre>
<p>With these options, when an <strong>OutOfMemoryError</strong> occurs, the JVM writes the heap dump to the file <code>/tmp/op.heapdump</code>; you'll then need to retrieve the file from the node on which the operator was running.</p>
<p>You can use the tool <code>jmap</code> (bundled with the JDK) to get a heap dump from a running container. Depending on the environment, you may need to run it as root and/or use the <code>-F</code> option. Following is a sample invocation on the sandbox:</p>
<pre><code>dtadmin@dtbox:~$ sudo jmap -dump:format=b,file=dump.bin -F 15557
Attaching to process ID 15557, please wait...
Debugger attached successfully.
Server compiler detected.
JVM version is 24.79-b02
Dumping heap to dump.bin ...
Heap dump file created
</code></pre>
<p>The heap dump shows the content of the entire heap in binary form and, as such, is not human readable and needs special tools such as
<a href="http://docs.oracle.com/javase/7/docs/technotes/tools/share/jhat.html">jhat</a> or <a href="http://www.eclipse.org/mat/downloads.php">MAT</a> to analyze it.</p>
<p>The former (<code>jhat</code>) is bundled as part of the JDK distribution, so it is very convenient to use. When run on a file containing a heap dump, it parses the file and makes the data viewable via a browser on port 7000 of the local host. Here is a typical run:</p>
<pre><code>tmp: jhat op.heapdump 
Reading from op.heapdump...
Dump file created Fri Feb 26 14:06:48 PST 2016
Snapshot read, resolving...
Resolving 70966 objects...
Chasing references, expect 14 dots..............
Eliminating duplicate references..............
Snapshot resolved.
Started HTTP server on port 7000
Server is ready.
</code></pre>
<p>It is important to remember that a heap dump is different from a thread dump. The latter shows the stack trace of every thread running in the container and is useful when threads are deadlocked. Additional information on tools related to both types of dumps is available
<a href="http://www.oracle.com/technetwork/java/javase/matrix6-unix-137789.html">here</a>.</p>
<h1 id="support">Support</h1>
<h2 id="do-you-need-help">Do you need help?</h2>
<p>You can contact us at <a href="https://www.datatorrent.com/contact">https://www.datatorrent.com/contact</a></p>
              
            </div>
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
        <a href="../release_notes/" class="btn btn-neutral float-right" title="Release Notes">Next <span class="icon icon-circle-arrow-right"></span></a>
      
      
        <a href="../apexcli/" class="btn btn-neutral" title="Apex CLI"><span class="icon icon-circle-arrow-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <!-- Copyright etc -->
    
  </div>

  <div class="footer">Copyright &#169; 2018 DataTorrent</div>
  <div class="footer">Apache, Hadoop, Apex, Yarn, HDFS and the Hadoop elephant and Apache project logos are either registered trademarks or trademarks of the Apache Software Foundation in the United States or other countries.</div>
</footer>
      
        </div>
      </div>

    </section>

  </div>

  <div class="rst-versions" role="note" style="cursor: pointer">
  <div class="version-select">
    <div class="version-select__bar">
      v: <span class="version-select__bar-version"></span>
      <i class="fa fa-caret-down"></i>
    </div>
    <div class="version-select__menu">
      <dl class="version-select__menu-versions">
        <dt>Versions</dt>
        <dd><a class="version-select__menu-versions-latest version" href="#">latest</a></dd>
        <!-- append versions here -->
      </dl>
    </div>
  </div>
</div>
    <script>var base_url = '..';</script>
    <script src="../js/theme.js" defer></script>
      <script src="../search/require.js" defer></script>
      <script src="../search/search.js" defer></script>

</body>
</html>
